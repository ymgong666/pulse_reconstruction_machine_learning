{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluate_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j81ye3JZS3t"
      },
      "source": [
        "\"\"\"\n",
        "This code evaluates the L1 loss of our model and the ResNet base model with a dataset has evenly distributed pulse FWHMs from 25fs ~ 70fs\n",
        "\"\"\"\n",
        "####### Predict the FWHM of arbitrary-duration pulses with MultiRes \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import csv\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import random\n",
        "import torchvision\n",
        "from torchvision.transforms import Compose, CenterCrop, ToTensor, Resize, Normalize\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#---checkpoint\n",
        "def save_checkpoint(model, epoch, checkpoint_dir, stats):\n",
        "    \"\"\"\n",
        "    Save model checkpoint.\n",
        "    \"\"\"\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'stats': stats,\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    filename = os.path.join(checkpoint_dir,\n",
        "                            'epoch={}.checkpoint.pth.tar'.format(epoch))\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "def restore_checkpoint(model, checkpoint_dir, cuda=False, force=False, pretrain=False):\n",
        "    \"\"\"\n",
        "    If a checkpoint exists, restores the PyTorch model from the checkpoint.\n",
        "    Returns the model, the current epoch, and training losses.\n",
        "    \"\"\"\n",
        "    def get_epoch(cp):\n",
        "        return int(cp.split('epoch=')[-1].split('.checkpoint.pth.tar')[0])\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    cp_files = [file_ for file_ in os.listdir(checkpoint_dir)\n",
        "                if file_.startswith('epoch=') and file_.endswith('.checkpoint.pth.tar')]\n",
        "    cp_files.sort(key=lambda x: get_epoch(x))\n",
        "\n",
        "    if not cp_files:\n",
        "        print('No saved model parameters found')\n",
        "        if force:\n",
        "            raise Exception('Checkpoint not found')\n",
        "        else:\n",
        "            return model, 0, []\n",
        "\n",
        "    # Find latest epoch\n",
        "    epochs = [get_epoch(cp) for cp in cp_files]\n",
        "\n",
        "    if not force:\n",
        "        epochs = [0] + epochs\n",
        "        print('Which epoch to load from? Choose from epochs below:')\n",
        "        print(epochs)\n",
        "        print('Enter 0 to train from scratch.')\n",
        "        print(\">> \", end='')\n",
        "        inp_epoch = int(input())\n",
        "        if inp_epoch not in epochs:\n",
        "            raise Exception(\"Invalid epoch number\")\n",
        "        if inp_epoch == 0:\n",
        "            print(\"Checkpoint not loaded\")\n",
        "            clear_checkpoint(checkpoint_dir)\n",
        "            return model, 0, []\n",
        "    else:\n",
        "        print('Which epoch to load from? Choose from epochs below:')\n",
        "        print(epochs)\n",
        "        print(\">> \", end='')\n",
        "        inp_epoch = int(input())\n",
        "        if inp_epoch not in epochs:\n",
        "            raise Exception(\"Invalid epoch number\")\n",
        "\n",
        "    filename = os.path.join(checkpoint_dir, 'epoch={}.checkpoint.pth.tar'.format(inp_epoch))\n",
        "\n",
        "    print(\"Loading from checkpoint {}\".format(filename))\n",
        "\n",
        "    if cuda:\n",
        "        checkpoint = torch.load(filename)\n",
        "    else:\n",
        "        # Load GPU model on CPU\n",
        "        checkpoint = torch.load(filename, map_location=lambda storage, loc: storage)\n",
        "\n",
        "    try:\n",
        "        stats = checkpoint['stats']\n",
        "        if pretrain:\n",
        "            model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
        "        else:\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "        print(\"=> Successfully restored checkpoint (trained for {} epochs)\".format(checkpoint['epoch']))\n",
        "    except:\n",
        "        print(\"=> Checkpoint not successfully restored\")\n",
        "        raise\n",
        "\n",
        "    return model, inp_epoch, stats\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "def clear_checkpoint(checkpoint_dir):\n",
        "    \"\"\"\n",
        "    Delete all checkpoints in directory.\n",
        "    \"\"\"\n",
        "    filelist = [f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth.tar\")]\n",
        "    for f in filelist:\n",
        "        os.remove(os.path.join(checkpoint_dir, f))\n",
        "\n",
        "    print(\"Checkpoint successfully removed\")\n",
        "\n",
        "#----plotter\n",
        "class Plotter:\n",
        "    def __init__(self, stats=[], name='CNN'):\n",
        "        self.stats = stats\n",
        "        self.name = name\n",
        "        self.axes = self.make_cnn_training_plot()\n",
        "\n",
        "    def make_cnn_training_plot(self):\n",
        "        \"\"\"\n",
        "        Runs the setup for an interactive matplotlib graph that logs the loss and accuracy\n",
        "        \"\"\"\n",
        "        print('Setting up interactive graph...')\n",
        "        plt.ion()\n",
        "        self.fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "        plt.suptitle(self.name + ' Training')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Accuracy')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Mean Loss')\n",
        "        return axes\n",
        "\n",
        "    def log_cnn_training(self, epoch, csv_location='/content/drive/My Drive/MachineLearningProject2020/CSV/multires_data.csv'):\n",
        "        \"\"\"\n",
        "        Logs the validation accuracy and loss to the terminal - Not currently doing the CSV logging\n",
        "        \"\"\"\n",
        "        valid_acc, valid_loss, train_acc, train_loss = self.stats[-1]\n",
        "        print('Epoch {}'.format(epoch))\n",
        "        print('\\tValidation Loss: {}'.format(valid_loss))\n",
        "        print('\\tValidation Accuracy: {}'.format(valid_acc))\n",
        "        print('\\tTrain Loss: {}'.format(train_loss))\n",
        "        print('\\tTrain Accuracy: {}'.format(train_acc))\n",
        "        \n",
        "    def update_cnn_training_plot(self, epoch):\n",
        "        \"\"\"\n",
        "        Updates the training plot with a new data point for loss and accuracy\n",
        "        \"\"\"\n",
        "        xrange = range(epoch - len(self.stats) + 1, epoch)\n",
        "        self.axes[0].plot(xrange, [s[0] for s in self.stats[1:]], linestyle='--', marker='o', color='b')\n",
        "        self.axes[0].plot(xrange, [s[2] for s in self.stats[1:]], linestyle='--', marker='o', color='r')\n",
        "        self.axes[1].plot(xrange, [s[1] for s in self.stats[1:]], linestyle='--', marker='o', color='b')\n",
        "        self.axes[1].plot(xrange, [s[3] for s in self.stats[1:]], linestyle='--', marker='o', color='r')\n",
        "        self.axes[0].legend(['Validation', 'Train'])\n",
        "        self.axes[1].legend(['Validation', 'Train'])\n",
        "        plt.pause(0.00001)\n",
        "\n",
        "    def save_cnn_training_plot(self):\n",
        "        \"\"\"\n",
        "        Saves the training plot to a file\n",
        "        \"\"\"\n",
        "        self.fig.savefig(self.name + '_training_plot.png', dpi=200)\n",
        "\n",
        "    def hold_training_plot(self):\n",
        "        \"\"\"\n",
        "        Keep the program alive to display the training plot\n",
        "        \"\"\"\n",
        "        plt.ioff()\n",
        "        plt.show()\n",
        "\n",
        "#---dataset\n",
        "class FROGDataset:\n",
        "    \"\"\"\n",
        "    FROG Dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size=4, dataset_path='/content/drive/MyDrive/MachineLearningProject2020/FROG_uniform_pulse_duration'):\n",
        "        self.batch_size = batch_size\n",
        "        self.dataset_path = dataset_path\n",
        "        self.train_dataset = self.get_train_numpy()\n",
        "        self.x_mean, self.x_std = self.compute_train_statistics()\n",
        "        self.transform = self.get_transforms()\n",
        "        self.train_loader, self.val_loader = self.get_dataloaders()\n",
        "        \n",
        "\n",
        "    def get_train_numpy(self):\n",
        "        train_dataset = train_data\n",
        "        return train_dataset\n",
        "\n",
        "    def compute_train_statistics(self):\n",
        "        # TODO (part a): compute per-channel mean and std with respect to self.train_dataset\n",
        "        print(self.train_dataset.shape) # should be a (8000 x 64 x 64) array\n",
        "        x_mean = np.array(np.mean(self.train_dataset))  # per-channel mean // only one channel of values\n",
        "        x_std = np.array(np.std(self.train_dataset))  # per-channel std\n",
        "        return x_mean, x_std\n",
        "\n",
        "    def get_transforms(self):\n",
        "        # TODO (part a): fill in the data transforms\n",
        "        transform_list = [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.x_mean,self.x_std)\n",
        "        ]\n",
        "        transform = transforms.Compose(transform_list)\n",
        "        return transform\n",
        "\n",
        "    def get_dataloaders(self):\n",
        "        train_dataset = train_data\n",
        "        train_img = np.zeros((len(train_dataset),3,64,64)) # 3 channels for CNN\n",
        "        train_label = train_labels # using the one-hot labels (10x1 numpy array)\n",
        "        for i in range(len(train_dataset)):\n",
        "            image = train_dataset[i,:,:]\n",
        "            image_temp = np.array([image,image,image])\n",
        "            train_img[i] = image_temp\n",
        "        train_img = torch.from_numpy(train_img).float()\n",
        "        train_label = torch.from_numpy(train_label).float()\n",
        "        train_set = torch.utils.data.TensorDataset(train_img,train_label)\n",
        "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        # validation set\n",
        "        val_dataset = val_data\n",
        "        val_img = np.zeros((len(val_dataset),3,64,64))\n",
        "        val_label = val_labels # using the one-hot labels (10x1 numpy array)\n",
        "        for i in range(len(val_dataset)):\n",
        "            image = val_dataset[i,:,:]\n",
        "            image_temp = np.array([image,image,image])\n",
        "            val_img[i] = image_temp\n",
        "        val_img = torch.from_numpy(val_img).float()\n",
        "        val_label = torch.from_numpy(val_label).float()\n",
        "        val_set = torch.utils.data.TensorDataset(val_img,val_label)\n",
        "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        return train_loader, val_loader\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO (part b): define layers\n",
        "        self.mr1_11 = nn.Conv2d(3, 3, 11, stride=2, padding=37)  # multires layer 1 -> 11x11 filter\n",
        "        self.mr1_7 = nn.Conv2d(3, 3, 7, stride=2, padding=35)  # multires layer 1 -> 7x7 filter\n",
        "        self.mr1_5 = nn.Conv2d(3, 3, 5, stride=2, padding=34)  # multires layer 1 -> 5x5 filter\n",
        "        self.mr1_3 = nn.Conv2d(3, 3, 3, stride=2, padding=33)  # multires layer 1 -> 3x3 filter\n",
        "        self.conv1 = nn.Conv2d(12, 24, 5, stride=2, padding=2)  # convolutional layer 1\n",
        "        self.mr2_11 = nn.Conv2d(24, 24, 11, stride=2, padding=21)  # multires layer 2 -> 11x11 filter\n",
        "        self.mr2_7 = nn.Conv2d(24, 24, 7, stride=2, padding=19)  # multires layer 2 -> 7x7 filter\n",
        "        self.mr2_5 = nn.Conv2d(24, 24, 5, stride=2, padding=18)  # multires layer 2 -> 5x5 filter\n",
        "        self.mr2_3 = nn.Conv2d(24, 24, 3, stride=2, padding=17)  # multires layer 2 -> 3x3 filter\n",
        "        self.conv2 = nn.Conv2d(96, 192, 5, stride=2, padding=2)  # convolutional layer 2\n",
        "        self.mr3_11 = nn.Conv2d(192, 192, 11, stride=2, padding=13)  # multires layer 3 -> 11x11 filter\n",
        "        self.mr3_7 = nn.Conv2d(192, 192, 7, stride=2, padding=11)  # multires layer 3 -> 7x7 filter\n",
        "        self.mr3_5 = nn.Conv2d(192, 192, 5, stride=2, padding=10)  # multires layer 3 -> 5x5 filter\n",
        "        self.mr3_3 = nn.Conv2d(192, 192, 3, stride=2, padding=9)  # multires layer 3 -> 3x3 filter\n",
        "        self.conv3 = nn.Conv2d(768, 1536, 5, stride=2, padding=2)  # convolutional layer 3\n",
        "        self.fc1 = nn.Linear(1536 * 8 * 8, 512)  # fully connected layer 1\n",
        "        self.fc2 = nn.Linear(512, 1)  # fully connected layer 2 (output layer for pulse width prediction)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for conv in [self.conv1, self.conv2, self.conv3]:\n",
        "            C_in = conv.weight.size(1)\n",
        "            nn.init.normal_(conv.weight, 0.0, 1 / math.sqrt(5 * 5 * C_in))\n",
        "            nn.init.constant_(conv.bias, 0.0)\n",
        "\n",
        "        for mr11 in [self.mr1_11, self.mr2_11, self.mr3_11]:\n",
        "            C_in = mr11.weight.size(1)\n",
        "            nn.init.normal_(mr11.weight, 0.0, 1 / math.sqrt(11 * 11 * C_in))\n",
        "            nn.init.constant_(mr11.bias, 0.0)\n",
        "\n",
        "        for mr7 in [self.mr1_7, self.mr2_7, self.mr3_7]:\n",
        "            C_in = mr7.weight.size(1)\n",
        "            nn.init.normal_(mr7.weight, 0.0, 1 / math.sqrt(7 * 7 * C_in))\n",
        "            nn.init.constant_(mr7.bias, 0.0)\n",
        "\n",
        "        for mr5 in [self.mr1_5, self.mr2_5, self.mr3_5]:\n",
        "            C_in = mr5.weight.size(1)\n",
        "            nn.init.normal_(mr5.weight, 0.0, 1 / math.sqrt(5 * 5 * C_in))\n",
        "            nn.init.constant_(mr5.bias, 0.0)       \n",
        "\n",
        "        for mr3 in [self.mr1_3, self.mr2_3, self.mr3_3]:\n",
        "            C_in = mr3.weight.size(1)\n",
        "            nn.init.normal_(mr3.weight, 0.0, 1 / math.sqrt(3 * 3 * C_in))\n",
        "            nn.init.constant_(mr3.bias, 0.0)\n",
        "\n",
        "        for fc in [self.fc1, self.fc2]:\n",
        "            F_in = fc.weight.size(1)\n",
        "            nn.init.normal_(fc.weight, 0.0, 1 / math.sqrt(F_in))\n",
        "            nn.init.constant_(fc.bias, 0.0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        z1 = self.mr1_11(x)\n",
        "        z2 = self.mr1_7(x)\n",
        "        z3 = self.mr1_5(x)\n",
        "        z4 = self.mr1_3(x)\n",
        "        z = F.relu(torch.cat((z1,z2,z3,z4),dim=1))\n",
        "\n",
        "        z = F.relu(self.conv1(z))\n",
        "        z5 = self.mr2_11(z)\n",
        "        z6 = self.mr2_7(z)\n",
        "        z7 = self.mr2_5(z)\n",
        "        z8 = self.mr2_3(z)\n",
        "        z = F.relu(torch.cat((z5,z6,z7,z8),dim=1))\n",
        "\n",
        "        z = F.relu(self.conv2(z))\n",
        "        z9 = self.mr3_11(z)\n",
        "        z10 = self.mr3_7(z)\n",
        "        z11 = self.mr3_5(z)\n",
        "        z12 = self.mr3_3(z)\n",
        "        z = F.relu(torch.cat((z9,z10,z11,z12),dim=1))\n",
        "\n",
        "        z = F.relu(self.conv3(z))\n",
        "        z = z.view(-1, 1536 * 8 * 8)\n",
        "        z = F.relu(self.fc1(z))\n",
        "        z = self.fc2(z)\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # import FROGDataset\n",
        "    net = CNN()\n",
        "    net = net.to(device)\n",
        "    print(net)\n",
        "    print('Number of CNN parameters: {}'.format(count_parameters(net)))\n",
        "\n",
        "#---train\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "def predictions(logits):\n",
        "    \"\"\"\n",
        "    Compute the predictions from the model.\n",
        "    Inputs:\n",
        "        - logits: output of our model based on some input, tensor with shape=(batch_size, num_features)\n",
        "    Returns:\n",
        "        - pred: predictions of our model, tensor with shape=(batch_size,num_features)\n",
        "    \"\"\"\n",
        "    return logits\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute the accuracy given true and predicted labels.\n",
        "    Inputs:\n",
        "        - y_true: true labels, tensor with shape=(num_examples)\n",
        "        - y_pred: predicted labels, tensor with shape=(num_examples)\n",
        "    Returns:\n",
        "        - acc: accuracy, float\n",
        "    \"\"\"\n",
        "\n",
        "    return 0.0\n",
        "\n",
        "def _train_epoch(train_loader, model, criterion, optimizer):\n",
        "    \"\"\"\n",
        "    Train the model for one iteration through the train set.\n",
        "    \"\"\"\n",
        "    \n",
        "    for i, (X, y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X.to(device))\n",
        "        loss = criterion(output, y.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def train(config, val_data, model):\n",
        "    criterion = torch.nn.L1Loss()\n",
        "    learning_rate = config['learning_rate']\n",
        "    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "    print('Loading model...')\n",
        "    force = config['ckpt_force'] if 'ckpt_force' in config else False\n",
        "    model, start_epoch, stats = restore_checkpoint(model, config['ckpt_path'], force=force)\n",
        "    model.eval()\n",
        "    \n",
        "    pred = model(val_data)\n",
        "\n",
        "    return pred\n",
        "    print('Finished Training')\n",
        "if __name__ == '__main__':\n",
        "    # define config parameters for training\n",
        "    config = {\n",
        "        'batch_size': 4,\n",
        "        'ckpt_path': '/content/drive/MyDrive/MultiRes',  # directory to save our model checkpoints\n",
        "        'num_epoch': 40,                 # number of epochs for training\n",
        "        'learning_rate': 1e-5,           # learning rate\n",
        "        'plot_name': 'Multi-Res'        # plot name\n",
        "    }\n",
        "    model = CNN()\n",
        "    df = pd.read_pickle('/content/drive/MyDrive/Test_domain_generalization/Pyret_Labels_for_CNN_5_15_duration_1000.pkl')\n",
        "    np.random.seed(5)\n",
        "    idx =np.random.randint(1000, size=(600))\n",
        "    val_data = np.tile(np.expand_dims(df.iloc[0,1][idx,:,:],axis = 1),[1,3,1,1])\n",
        "    val_label = np.array(df.iloc[0,2])[idx]\n",
        "    val_label = torch.tensor(val_label)\n",
        "    val_data = torch.tensor(val_data).float()\n",
        "    val_data = val_data.to(device)\n",
        "    val_labelll = np.array(df.iloc[0,0])[idx,:]\n",
        "    len_pred = train(config,val_data, model.to(device))\n",
        "    query_idx = len_pred.cpu().detach().numpy().astype(int) - 5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_V8g-uDdY0D"
      },
      "source": [
        "\"\"\"\n",
        "Save the weights and biases of the FC layers queried based on the MultiRes predictions\n",
        "\"\"\"\n",
        "    fc_layers = pd.read_pickle('/content/drive/MyDrive/Test_domain_generalization/fc_layers.pkl')\n",
        "    fc_layers1_bias = fc_layers.loc[0, 'fc_layers1_bias']\n",
        "    fc_layers2_bias = fc_layers.loc[0, 'fc_layers2_bias']\n",
        "    fc_layers3_bias = fc_layers.loc[0, 'fc_layers3_bias']\n",
        "    fc_layers1_weight = fc_layers.loc[0, 'fc_layers1_weight']\n",
        "    fc_layers2_weight = fc_layers.loc[0, 'fc_layers2_weight']\n",
        "    fc_layers3_weight = fc_layers.loc[0, 'fc_layers3_weight']\n",
        "    fc_layers1_b = np.squeeze(fc_layers1_bias[query_idx,:]).cpu().detach().numpy()\n",
        "    fc_layers2_b = np.squeeze(fc_layers2_bias[query_idx,:]).cpu().detach().numpy()\n",
        "    fc_layers3_b = np.squeeze(fc_layers3_bias[query_idx,:]).cpu().detach().numpy()\n",
        "    fc_layers1_w = np.squeeze(fc_layers1_weight[query_idx,:,:]).cpu().detach().numpy()\n",
        "    fc_layers2_w = np.squeeze(fc_layers2_weight[query_idx,:, :]).cpu().detach().numpy()\n",
        "    fc_layers3_w = np.squeeze(fc_layers3_weight[query_idx,:, :]).cpu().detach().numpy()\n",
        "    fc_layers1_w = np.swapaxes(fc_layers1_w,1,2)\n",
        "    fc_layers2_w = np.swapaxes(fc_layers2_w,1,2)\n",
        "    fc_layers3_w = np.swapaxes(fc_layers3_w,1,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APQ-tMq-f91r"
      },
      "source": [
        "\"\"\"\n",
        "Evaluate the loss for our model\n",
        "\"\"\"\n",
        "def load_pretrained(dict_path):\n",
        "    Resnet18 = models.resnet18(pretrained=False)\n",
        "    if (dict_path != None):\n",
        "        Resnet18.load_state_dict(torch.load(dict_path))\n",
        "    for param in Resnet18.parameters():\n",
        "        param.requires_grad = True\n",
        "    n_inputs = Resnet18.fc.in_features\n",
        "    Resnet18.fc = torch.nn.Linear(512,1000)\n",
        "    return Resnet18\n",
        "\n",
        "def train(config, dataset, model):\n",
        "    print('Loading model...') \n",
        "    force = config['ckpt_force'] if 'ckpt_force' in config else False\n",
        "    model, start_epoch, stats = restore_checkpoint(model, config['ckpt_path'], force=force)\n",
        "    model = nn.Sequential(*list(model.children())[:-1])\n",
        "    print('Finished Training')\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    config = {\n",
        "        'batch_size': 4,\n",
        "        'ckpt_path': '/content/drive/MyDrive/checkpointsResNet4e-4_120_24_duration_5_15_2fc_long/transfer',\n",
        "        'plot_name': 'TransferCPU_4_4e-3_50EP',\n",
        "        'dict_path': '/content/drive/MyDrive/ResNet18.pt',\n",
        "\n",
        "    }\n",
        "    model = load_pretrained(config['dict_path'])\n",
        "    lin = model.fc\n",
        "    new_lin = nn.Sequential(\n",
        "        lin,\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(lin.out_features, 1000),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(1000, 128)\n",
        "    )\n",
        "    model.fc = new_lin\n",
        "    model = model.cuda()\n",
        "    model = train(config, val_data, model)  \n",
        "    val_pr = model(val_data)\n",
        "    Leaky = nn.LeakyReLU(0.2)\n",
        "    val_pr= val_pr.cpu().detach().numpy()\n",
        "    val_pr = np.squeeze(val_pr)\n",
        "    val_pr = np.expand_dims(val_pr,1)\n",
        "    fc_layers1_w = fc_layers1_w\n",
        "    inter1 = torch.tensor(np.squeeze(np.matmul(val_pr,fc_layers1_w))+ fc_layers1_b)\n",
        "    inter1 = Leaky(inter1).cpu().detach().numpy()\n",
        "\n",
        "    inter2 = torch.tensor(np.squeeze(np.matmul(np.expand_dims(inter1,1),fc_layers2_w))+ fc_layers2_b)\n",
        "    inter2 = Leaky(inter2).cpu().detach().numpy()\n",
        "    inter3 = np.squeeze(np.matmul(np.expand_dims(inter2,1),fc_layers3_w))+ fc_layers3_b\n",
        "    plt.plot(inter3[2,:])\n",
        "    plt.plot(val_labelll[2,:])\n",
        "predd = torch.tensor(inter3)\n",
        "vall = torch.tensor(val_labelll)\n",
        "L1 = nn.L1Loss()\n",
        "print('The loss of our model is: ',L1(predd,vall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0jA9VX2f_Ef"
      },
      "source": [
        "\"\"\"\n",
        "Evaluate the loss for the ResNet base model\n",
        "\"\"\"\n",
        "def train(config, dataset, model):\n",
        "\n",
        "    print('Loading model...') \n",
        "    force = config['ckpt_force'] if 'ckpt_force' in config else False\n",
        "    model, start_epoch, stats = restore_checkpoint(model, config['ckpt_path'], force=force)\n",
        "    print('Finished Training')\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    config = {\n",
        "        'batch_size': 4,\n",
        "        'ckpt_path': '/content/drive/MyDrive/checkpointsResNet4e-4_120_24_duration_5_15_2fc_long/transfer',\n",
        "        'plot_name': 'TransferCPU_4_4e-3_50EP',\n",
        "        'dict_path': '/content/drive/MyDrive/ResNet18.pt',\n",
        "\n",
        "    }\n",
        "    model = load_pretrained(config['dict_path'])\n",
        "    lin = model.fc\n",
        "    new_lin = nn.Sequential(\n",
        "        lin,\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(lin.out_features, 1000),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(1000, 128)\n",
        "    )\n",
        "    model.fc = new_lin\n",
        "    model = model.cuda()\n",
        "    model = train(config, val_data, model)  \n",
        "    pred_base = model(val_data)\n",
        "    print(\"The loss of ResNet base model is: \", L1(pred_base,vall.to('cuda')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}